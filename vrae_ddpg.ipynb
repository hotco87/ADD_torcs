{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from vrae import VRAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "s = np.load('./buffer_original_reward3/test_buffer_state.npy')\n",
    "a = np.load('./buffer_original_reward3/test_buffer_action.npy')\n",
    "r = np.load('./buffer_original_reward3/test_buffer_reward.npy')\n",
    "s_ = np.load('./buffer_original_reward3/test_buffer_next_state.npy')\n",
    "not_done = np.load('./buffer_original_reward3/test_buffer_not_done.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode length min: 11, max: 301\n"
     ]
    }
   ],
   "source": [
    "idx_done = np.array(np.where(not_done.reshape(-1) != 1))\n",
    "idx_epi_start = np.insert(idx_done + 1, 0, 0)\n",
    "idx_epi_end = np.append(idx_done, not_done.size)\n",
    "epi_idxes = zip(idx_epi_start, idx_epi_end)\n",
    "\n",
    "min_sequence_len = np.min(np.diff(idx_done, 1))\n",
    "max_sequence_len = np.max(np.diff(idx_done, 1))\n",
    "\n",
    "print('episode length min: {}, max: {}'.format(min_sequence_len, max_sequence_len))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# episodes = []\n",
    "# for start, finish in epi_idxes:\n",
    "#     current_episode = s[start:finish]\n",
    "#     padded_current_episode = np.concatenate(\n",
    "#         (current_episode, np.zeros((max_sequence_len - current_episode.shape[0], 29))), axis=0)\n",
    "#     episodes.append(padded_current_episode)\n",
    "# episodes = np.stack(episodes)\n",
    "\n",
    "seq_len = 8\n",
    "episodes = []\n",
    "for start, finish in epi_idxes:\n",
    "    current_episode = s[start:finish]\n",
    "    frag = [np.array(current_episode[i:i + seq_len]) for i in range(len(current_episode) - seq_len)]\n",
    "    episodes.append(np.stack(frag))\n",
    "episodes = np.concatenate(episodes)\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(episodes))\n",
    "test_dataset = TensorDataset(torch.from_numpy(episodes))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "hidden_size = 90\n",
    "hidden_layer_depth = 1\n",
    "latent_length = 64\n",
    "batch_size = 32\n",
    "learning_rate = 0.0005\n",
    "n_epochs = 50\n",
    "dropout_rate = 0.2\n",
    "optimizer = 'Adam'  # options: ADAM, SGD\n",
    "cuda = True  # options: True, False\n",
    "print_every = 200\n",
    "clip = True  # options: True, False\n",
    "max_grad_norm = 5\n",
    "loss = 'MSELoss'  # options: SmoothL1Loss, MSELoss\n",
    "block = 'LSTM'  # options: LSTM, GRU"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "sequence_length = episodes.shape[1]\n",
    "number_of_features = episodes.shape[2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcm/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/bcm/.local/lib/python3.8/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "model = VRAE(sequence_length=sequence_length,\n",
    "             number_of_features=number_of_features,\n",
    "             hidden_size=hidden_size,\n",
    "             hidden_layer_depth=hidden_layer_depth,\n",
    "             latent_length=latent_length,\n",
    "             batch_size=batch_size,\n",
    "             learning_rate=learning_rate,\n",
    "             n_epochs=n_epochs,\n",
    "             dropout_rate=dropout_rate,\n",
    "             optimizer=optimizer,\n",
    "             cuda=cuda,\n",
    "             print_every=print_every,\n",
    "             clip=clip,\n",
    "             max_grad_norm=max_grad_norm,\n",
    "             loss=loss,\n",
    "             block=block)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Batch [ 200/2943], loss = 216.9197, recon_loss = 215.4236, kl_loss =   1.4961\n",
      "Batch [ 400/2943], loss = 104.9424, recon_loss = 102.9449, kl_loss =   1.9975\n",
      "Batch [ 600/2943], loss = 100.2061, recon_loss =  97.9249, kl_loss =   2.2812\n",
      "Batch [ 800/2943], loss =  85.7791, recon_loss =  83.2913, kl_loss =   2.4878\n",
      "Batch [1000/2943], loss = 105.5818, recon_loss = 103.0461, kl_loss =   2.5357\n",
      "Batch [1200/2943], loss = 115.6962, recon_loss = 113.1481, kl_loss =   2.5481\n",
      "Batch [1400/2943], loss = 127.0886, recon_loss = 124.3764, kl_loss =   2.7122\n",
      "Batch [1600/2943], loss =  90.0298, recon_loss =  87.4566, kl_loss =   2.5732\n",
      "Batch [1800/2943], loss =  86.3031, recon_loss =  83.6178, kl_loss =   2.6853\n",
      "Batch [2000/2943], loss =  82.8210, recon_loss =  80.2015, kl_loss =   2.6195\n",
      "Batch [2200/2943], loss =  75.3398, recon_loss =  72.6242, kl_loss =   2.7156\n",
      "Batch [2400/2943], loss =  60.3483, recon_loss =  57.6662, kl_loss =   2.6821\n",
      "Batch [2600/2943], loss =  98.1744, recon_loss =  95.4487, kl_loss =   2.7258\n",
      "Batch [2800/2943], loss =  98.2295, recon_loss =  95.4624, kl_loss =   2.7671\n",
      "Average loss: 122.2282\n",
      "Epoch: 1\n",
      "Batch [ 200/2943], loss =  61.8573, recon_loss =  59.1958, kl_loss =   2.6615\n",
      "Batch [ 400/2943], loss =  67.2374, recon_loss =  64.5316, kl_loss =   2.7057\n",
      "Batch [ 600/2943], loss =  92.4156, recon_loss =  89.6075, kl_loss =   2.8081\n",
      "Batch [ 800/2943], loss =  62.5406, recon_loss =  59.7336, kl_loss =   2.8070\n",
      "Batch [1000/2943], loss =  64.4485, recon_loss =  61.6305, kl_loss =   2.8180\n",
      "Batch [1200/2943], loss =  77.8762, recon_loss =  75.0275, kl_loss =   2.8487\n",
      "Batch [1400/2943], loss =  60.4584, recon_loss =  57.6809, kl_loss =   2.7774\n",
      "Batch [1600/2943], loss =  68.7844, recon_loss =  66.0066, kl_loss =   2.7778\n",
      "Batch [1800/2943], loss =  64.9754, recon_loss =  62.0806, kl_loss =   2.8948\n",
      "Batch [2000/2943], loss =  72.5453, recon_loss =  69.6941, kl_loss =   2.8511\n",
      "Batch [2200/2943], loss =  66.5178, recon_loss =  63.6438, kl_loss =   2.8741\n",
      "Batch [2400/2943], loss =  53.0930, recon_loss =  50.2562, kl_loss =   2.8368\n",
      "Batch [2600/2943], loss =  48.5023, recon_loss =  45.6699, kl_loss =   2.8323\n",
      "Batch [2800/2943], loss =  51.8045, recon_loss =  48.9196, kl_loss =   2.8849\n",
      "Average loss: 63.4127\n",
      "Epoch: 2\n",
      "Batch [ 200/2943], loss =  50.0332, recon_loss =  47.2326, kl_loss =   2.8006\n",
      "Batch [ 400/2943], loss =  55.3690, recon_loss =  52.4943, kl_loss =   2.8747\n",
      "Batch [ 600/2943], loss =  55.6559, recon_loss =  52.7107, kl_loss =   2.9452\n",
      "Batch [ 800/2943], loss =  51.2849, recon_loss =  48.4187, kl_loss =   2.8662\n",
      "Batch [1000/2943], loss =  47.7022, recon_loss =  44.8410, kl_loss =   2.8612\n",
      "Batch [1200/2943], loss =  47.2318, recon_loss =  44.3418, kl_loss =   2.8901\n",
      "Batch [1400/2943], loss =  42.1839, recon_loss =  39.3564, kl_loss =   2.8275\n",
      "Batch [1600/2943], loss =  39.1563, recon_loss =  36.3168, kl_loss =   2.8395\n",
      "Batch [1800/2943], loss =  48.8201, recon_loss =  45.9928, kl_loss =   2.8273\n",
      "Batch [2000/2943], loss =  33.4532, recon_loss =  30.6505, kl_loss =   2.8027\n",
      "Batch [2200/2943], loss =  44.3412, recon_loss =  41.4940, kl_loss =   2.8472\n",
      "Batch [2400/2943], loss =  38.3548, recon_loss =  35.5214, kl_loss =   2.8335\n",
      "Batch [2600/2943], loss =  38.4167, recon_loss =  35.5476, kl_loss =   2.8691\n",
      "Batch [2800/2943], loss =  31.2068, recon_loss =  28.3442, kl_loss =   2.8626\n",
      "Average loss: 47.9254\n",
      "Epoch: 3\n",
      "Batch [ 200/2943], loss =  53.3471, recon_loss =  50.4400, kl_loss =   2.9072\n",
      "Batch [ 400/2943], loss =  58.7474, recon_loss =  55.8524, kl_loss =   2.8950\n",
      "Batch [ 600/2943], loss =  30.8442, recon_loss =  27.9870, kl_loss =   2.8572\n",
      "Batch [ 800/2943], loss =  44.4229, recon_loss =  41.5317, kl_loss =   2.8912\n",
      "Batch [1000/2943], loss =  39.3125, recon_loss =  36.4416, kl_loss =   2.8709\n",
      "Batch [1200/2943], loss =  34.8230, recon_loss =  31.8939, kl_loss =   2.9291\n",
      "Batch [1400/2943], loss =  31.9594, recon_loss =  29.0733, kl_loss =   2.8860\n",
      "Batch [1600/2943], loss =  33.1972, recon_loss =  30.3391, kl_loss =   2.8581\n",
      "Batch [1800/2943], loss =  37.1100, recon_loss =  34.2110, kl_loss =   2.8990\n",
      "Batch [2000/2943], loss =  33.7041, recon_loss =  30.7635, kl_loss =   2.9405\n",
      "Batch [2200/2943], loss =  41.3641, recon_loss =  38.5167, kl_loss =   2.8474\n",
      "Batch [2400/2943], loss =  34.3609, recon_loss =  31.4185, kl_loss =   2.9424\n",
      "Batch [2600/2943], loss =  23.2125, recon_loss =  20.3494, kl_loss =   2.8632\n",
      "Batch [2800/2943], loss =  40.1067, recon_loss =  37.1396, kl_loss =   2.9671\n",
      "Average loss: 35.7604\n",
      "Epoch: 4\n",
      "Batch [ 200/2943], loss =  32.5115, recon_loss =  29.5880, kl_loss =   2.9235\n",
      "Batch [ 400/2943], loss =  28.8603, recon_loss =  25.9718, kl_loss =   2.8885\n",
      "Batch [ 600/2943], loss =  31.4009, recon_loss =  28.4603, kl_loss =   2.9405\n",
      "Batch [ 800/2943], loss =  27.0011, recon_loss =  24.0479, kl_loss =   2.9531\n",
      "Batch [1000/2943], loss =  25.5040, recon_loss =  22.6426, kl_loss =   2.8614\n",
      "Batch [1200/2943], loss =  26.9333, recon_loss =  23.9979, kl_loss =   2.9353\n",
      "Batch [1400/2943], loss =  27.2921, recon_loss =  24.3729, kl_loss =   2.9192\n",
      "Batch [1600/2943], loss =  32.9939, recon_loss =  30.0862, kl_loss =   2.9077\n",
      "Batch [1800/2943], loss =  22.2940, recon_loss =  19.4389, kl_loss =   2.8551\n",
      "Batch [2000/2943], loss =  23.2431, recon_loss =  20.3708, kl_loss =   2.8724\n",
      "Batch [2200/2943], loss =  26.3822, recon_loss =  23.5149, kl_loss =   2.8673\n",
      "Batch [2400/2943], loss =  26.2809, recon_loss =  23.4040, kl_loss =   2.8768\n",
      "Batch [2600/2943], loss =  31.3684, recon_loss =  28.4198, kl_loss =   2.9486\n",
      "Batch [2800/2943], loss =  27.8757, recon_loss =  24.9220, kl_loss =   2.9537\n",
      "Average loss: 28.3706\n",
      "Epoch: 5\n",
      "Batch [ 200/2943], loss =  29.8391, recon_loss =  26.9561, kl_loss =   2.8831\n",
      "Batch [ 400/2943], loss =  31.8278, recon_loss =  28.8853, kl_loss =   2.9425\n",
      "Batch [ 600/2943], loss =  29.4378, recon_loss =  26.4452, kl_loss =   2.9926\n",
      "Batch [ 800/2943], loss =  24.4557, recon_loss =  21.5914, kl_loss =   2.8642\n",
      "Batch [1000/2943], loss =  22.1376, recon_loss =  19.3204, kl_loss =   2.8172\n",
      "Batch [1200/2943], loss =  18.5751, recon_loss =  15.7004, kl_loss =   2.8747\n",
      "Batch [1400/2943], loss =  22.1158, recon_loss =  19.2510, kl_loss =   2.8647\n",
      "Batch [1600/2943], loss =  24.3451, recon_loss =  21.4239, kl_loss =   2.9211\n",
      "Batch [1800/2943], loss =  22.9431, recon_loss =  19.9909, kl_loss =   2.9521\n",
      "Batch [2000/2943], loss =  20.8562, recon_loss =  17.9460, kl_loss =   2.9102\n",
      "Batch [2200/2943], loss =  20.4009, recon_loss =  17.5392, kl_loss =   2.8617\n",
      "Batch [2400/2943], loss =  18.9336, recon_loss =  16.0702, kl_loss =   2.8635\n",
      "Batch [2600/2943], loss =  17.9750, recon_loss =  15.0828, kl_loss =   2.8921\n",
      "Batch [2800/2943], loss =  22.2093, recon_loss =  19.3587, kl_loss =   2.8507\n",
      "Average loss: 23.6331\n",
      "Epoch: 6\n",
      "Batch [ 200/2943], loss =  22.9810, recon_loss =  20.0769, kl_loss =   2.9041\n",
      "Batch [ 400/2943], loss =  22.1253, recon_loss =  19.2369, kl_loss =   2.8885\n",
      "Batch [ 600/2943], loss =  22.2392, recon_loss =  19.3495, kl_loss =   2.8896\n",
      "Batch [ 800/2943], loss =  17.0822, recon_loss =  14.2662, kl_loss =   2.8160\n",
      "Batch [1000/2943], loss =  23.2290, recon_loss =  20.3068, kl_loss =   2.9222\n",
      "Batch [1200/2943], loss =  18.0291, recon_loss =  15.1603, kl_loss =   2.8688\n",
      "Batch [1400/2943], loss =  18.3412, recon_loss =  15.5029, kl_loss =   2.8383\n",
      "Batch [1600/2943], loss =  21.1627, recon_loss =  18.3272, kl_loss =   2.8356\n",
      "Batch [1800/2943], loss =  20.9541, recon_loss =  18.0979, kl_loss =   2.8562\n",
      "Batch [2000/2943], loss =  20.4455, recon_loss =  17.4939, kl_loss =   2.9516\n",
      "Batch [2200/2943], loss =  18.8249, recon_loss =  15.9606, kl_loss =   2.8643\n",
      "Batch [2400/2943], loss =  23.1110, recon_loss =  20.2007, kl_loss =   2.9103\n",
      "Batch [2600/2943], loss =  20.1660, recon_loss =  17.2643, kl_loss =   2.9017\n",
      "Batch [2800/2943], loss =  17.6183, recon_loss =  14.8181, kl_loss =   2.8002\n",
      "Average loss: 20.3674\n",
      "Epoch: 7\n",
      "Batch [ 200/2943], loss =  20.1999, recon_loss =  17.3202, kl_loss =   2.8797\n",
      "Batch [ 400/2943], loss =  17.7547, recon_loss =  14.9114, kl_loss =   2.8432\n",
      "Batch [ 600/2943], loss =  15.7541, recon_loss =  12.8392, kl_loss =   2.9149\n",
      "Batch [ 800/2943], loss =  18.3860, recon_loss =  15.5698, kl_loss =   2.8162\n",
      "Batch [1000/2943], loss =  19.7987, recon_loss =  17.0358, kl_loss =   2.7629\n",
      "Batch [1200/2943], loss =  19.0688, recon_loss =  16.2707, kl_loss =   2.7981\n",
      "Batch [1400/2943], loss =  22.7522, recon_loss =  19.9422, kl_loss =   2.8100\n",
      "Batch [1600/2943], loss =  19.3550, recon_loss =  16.5009, kl_loss =   2.8541\n",
      "Batch [1800/2943], loss =  15.8737, recon_loss =  13.0230, kl_loss =   2.8507\n",
      "Batch [2000/2943], loss =  15.6887, recon_loss =  12.9384, kl_loss =   2.7502\n",
      "Batch [2200/2943], loss =  23.1757, recon_loss =  20.2929, kl_loss =   2.8828\n",
      "Batch [2400/2943], loss =  14.4087, recon_loss =  11.6645, kl_loss =   2.7442\n",
      "Batch [2600/2943], loss =  17.8308, recon_loss =  15.0465, kl_loss =   2.7844\n",
      "Batch [2800/2943], loss =  22.7628, recon_loss =  19.9177, kl_loss =   2.8451\n",
      "Average loss: 18.3857\n",
      "Epoch: 8\n",
      "Batch [ 200/2943], loss =  20.5255, recon_loss =  17.6812, kl_loss =   2.8443\n",
      "Batch [ 400/2943], loss =  17.1220, recon_loss =  14.3360, kl_loss =   2.7860\n",
      "Batch [ 600/2943], loss =  14.8866, recon_loss =  12.1009, kl_loss =   2.7857\n",
      "Batch [ 800/2943], loss =  15.9561, recon_loss =  13.2460, kl_loss =   2.7102\n",
      "Batch [1000/2943], loss =  16.9250, recon_loss =  14.1459, kl_loss =   2.7790\n",
      "Batch [1200/2943], loss =  17.9684, recon_loss =  15.1830, kl_loss =   2.7854\n",
      "Batch [1400/2943], loss =  17.0361, recon_loss =  14.2104, kl_loss =   2.8257\n",
      "Batch [1600/2943], loss =  20.1497, recon_loss =  17.3519, kl_loss =   2.7978\n",
      "Batch [1800/2943], loss =  15.5552, recon_loss =  12.8088, kl_loss =   2.7464\n",
      "Batch [2000/2943], loss =  22.4747, recon_loss =  19.6405, kl_loss =   2.8342\n",
      "Batch [2200/2943], loss =  15.8981, recon_loss =  13.1187, kl_loss =   2.7793\n",
      "Batch [2400/2943], loss =  14.9598, recon_loss =  12.2452, kl_loss =   2.7147\n",
      "Batch [2600/2943], loss =  15.0446, recon_loss =  12.2715, kl_loss =   2.7731\n",
      "Batch [2800/2943], loss =  15.1687, recon_loss =  12.3471, kl_loss =   2.8216\n",
      "Average loss: 16.9603\n",
      "Epoch: 9\n",
      "Batch [ 200/2943], loss =  15.0637, recon_loss =  12.3185, kl_loss =   2.7452\n",
      "Batch [ 400/2943], loss =  18.1816, recon_loss =  15.4571, kl_loss =   2.7245\n",
      "Batch [ 600/2943], loss =  14.5284, recon_loss =  11.8271, kl_loss =   2.7012\n",
      "Batch [ 800/2943], loss =  16.5009, recon_loss =  13.7958, kl_loss =   2.7051\n",
      "Batch [1000/2943], loss =  15.5234, recon_loss =  12.8600, kl_loss =   2.6635\n",
      "Batch [1200/2943], loss =  18.1182, recon_loss =  15.3293, kl_loss =   2.7890\n",
      "Batch [1400/2943], loss =  17.0253, recon_loss =  14.2585, kl_loss =   2.7667\n",
      "Batch [1600/2943], loss =  15.3500, recon_loss =  12.6685, kl_loss =   2.6815\n",
      "Batch [1800/2943], loss =  14.0923, recon_loss =  11.3809, kl_loss =   2.7114\n",
      "Batch [2000/2943], loss =  15.3572, recon_loss =  12.6904, kl_loss =   2.6668\n",
      "Batch [2200/2943], loss =  17.9493, recon_loss =  15.2738, kl_loss =   2.6755\n",
      "Batch [2400/2943], loss =  15.6025, recon_loss =  12.9408, kl_loss =   2.6617\n",
      "Batch [2600/2943], loss =  13.2122, recon_loss =  10.5595, kl_loss =   2.6528\n",
      "Batch [2800/2943], loss =  11.8991, recon_loss =   9.3395, kl_loss =   2.5596\n",
      "Average loss: 15.9161\n",
      "Epoch: 10\n",
      "Batch [ 200/2943], loss =  15.8362, recon_loss =  13.1130, kl_loss =   2.7232\n",
      "Batch [ 400/2943], loss =  16.1655, recon_loss =  13.5334, kl_loss =   2.6321\n",
      "Batch [ 600/2943], loss =  15.4597, recon_loss =  12.7476, kl_loss =   2.7120\n",
      "Batch [ 800/2943], loss =  17.4141, recon_loss =  14.7053, kl_loss =   2.7088\n",
      "Batch [1000/2943], loss =  15.0219, recon_loss =  12.4663, kl_loss =   2.5556\n",
      "Batch [1200/2943], loss =  16.1350, recon_loss =  13.5315, kl_loss =   2.6036\n",
      "Batch [1400/2943], loss =  16.7894, recon_loss =  14.1507, kl_loss =   2.6387\n",
      "Batch [1600/2943], loss =  10.0667, recon_loss =   7.5516, kl_loss =   2.5151\n",
      "Batch [1800/2943], loss =  14.5382, recon_loss =  11.9764, kl_loss =   2.5618\n",
      "Batch [2000/2943], loss =  13.5718, recon_loss =  10.9707, kl_loss =   2.6012\n",
      "Batch [2200/2943], loss =  13.5167, recon_loss =  10.8798, kl_loss =   2.6369\n",
      "Batch [2400/2943], loss =  13.3766, recon_loss =  10.7474, kl_loss =   2.6292\n",
      "Batch [2600/2943], loss =  14.6181, recon_loss =  12.0050, kl_loss =   2.6131\n",
      "Batch [2800/2943], loss =  11.7506, recon_loss =   9.1790, kl_loss =   2.5716\n",
      "Average loss: 15.0425\n",
      "Epoch: 11\n",
      "Batch [ 200/2943], loss =  14.2962, recon_loss =  11.7247, kl_loss =   2.5716\n",
      "Batch [ 400/2943], loss =  18.0243, recon_loss =  15.4614, kl_loss =   2.5629\n",
      "Batch [ 600/2943], loss =  17.6649, recon_loss =  15.0046, kl_loss =   2.6603\n",
      "Batch [ 800/2943], loss =  11.3647, recon_loss =   8.8724, kl_loss =   2.4923\n",
      "Batch [1000/2943], loss =  16.2285, recon_loss =  13.6682, kl_loss =   2.5603\n",
      "Batch [1200/2943], loss =  14.3435, recon_loss =  11.8382, kl_loss =   2.5053\n",
      "Batch [1400/2943], loss =  15.3631, recon_loss =  12.8083, kl_loss =   2.5548\n",
      "Batch [1600/2943], loss =  11.2180, recon_loss =   8.7211, kl_loss =   2.4969\n",
      "Batch [1800/2943], loss =  11.5862, recon_loss =   9.1399, kl_loss =   2.4463\n",
      "Batch [2000/2943], loss =  15.1193, recon_loss =  12.5866, kl_loss =   2.5327\n",
      "Batch [2200/2943], loss =  13.0763, recon_loss =  10.5696, kl_loss =   2.5067\n",
      "Batch [2400/2943], loss =  12.1241, recon_loss =   9.6296, kl_loss =   2.4946\n",
      "Batch [2600/2943], loss =  10.9012, recon_loss =   8.5101, kl_loss =   2.3910\n",
      "Batch [2800/2943], loss =  14.1590, recon_loss =  11.6812, kl_loss =   2.4778\n",
      "Average loss: 14.3651\n",
      "Epoch: 12\n",
      "Batch [ 200/2943], loss =  14.0079, recon_loss =  11.5673, kl_loss =   2.4406\n",
      "Batch [ 400/2943], loss =  18.5259, recon_loss =  16.0681, kl_loss =   2.4578\n",
      "Batch [ 600/2943], loss =  15.7570, recon_loss =  13.2770, kl_loss =   2.4800\n",
      "Batch [ 800/2943], loss =  16.3483, recon_loss =  13.8450, kl_loss =   2.5034\n",
      "Batch [1000/2943], loss =  16.2261, recon_loss =  13.7404, kl_loss =   2.4857\n",
      "Batch [1200/2943], loss =  14.8875, recon_loss =  12.3549, kl_loss =   2.5325\n",
      "Batch [1400/2943], loss =  13.0671, recon_loss =  10.6134, kl_loss =   2.4537\n",
      "Batch [1600/2943], loss =  16.4450, recon_loss =  14.0114, kl_loss =   2.4336\n",
      "Batch [1800/2943], loss =  11.3742, recon_loss =   8.9630, kl_loss =   2.4112\n",
      "Batch [2000/2943], loss =  16.3608, recon_loss =  13.9491, kl_loss =   2.4117\n",
      "Batch [2200/2943], loss =  14.0128, recon_loss =  11.6140, kl_loss =   2.3988\n",
      "Batch [2400/2943], loss =  17.8649, recon_loss =  15.4041, kl_loss =   2.4607\n",
      "Batch [2600/2943], loss =  11.4235, recon_loss =   9.0835, kl_loss =   2.3400\n",
      "Batch [2800/2943], loss =  11.2224, recon_loss =   8.8658, kl_loss =   2.3566\n",
      "Average loss: 13.7643\n",
      "Epoch: 13\n",
      "Batch [ 200/2943], loss =  11.0402, recon_loss =   8.6502, kl_loss =   2.3900\n",
      "Batch [ 400/2943], loss =   9.8933, recon_loss =   7.5930, kl_loss =   2.3003\n",
      "Batch [ 600/2943], loss =  14.7883, recon_loss =  12.3331, kl_loss =   2.4552\n",
      "Batch [ 800/2943], loss =  11.1072, recon_loss =   8.7477, kl_loss =   2.3595\n",
      "Batch [1000/2943], loss =  14.7525, recon_loss =  12.3906, kl_loss =   2.3619\n",
      "Batch [1200/2943], loss =  13.6754, recon_loss =  11.2755, kl_loss =   2.3999\n",
      "Batch [1400/2943], loss =  12.3482, recon_loss =  10.0639, kl_loss =   2.2843\n",
      "Batch [1600/2943], loss =  11.7673, recon_loss =   9.4204, kl_loss =   2.3469\n",
      "Batch [1800/2943], loss =  10.5416, recon_loss =   8.3034, kl_loss =   2.2382\n",
      "Batch [2000/2943], loss =  11.3893, recon_loss =   9.0733, kl_loss =   2.3160\n",
      "Batch [2200/2943], loss =  13.2523, recon_loss =  10.9634, kl_loss =   2.2890\n",
      "Batch [2400/2943], loss =  16.2582, recon_loss =  13.8832, kl_loss =   2.3750\n",
      "Batch [2600/2943], loss =  12.1200, recon_loss =   9.8759, kl_loss =   2.2441\n",
      "Batch [2800/2943], loss =  12.8186, recon_loss =  10.4765, kl_loss =   2.3421\n",
      "Average loss: 13.2434\n",
      "Epoch: 14\n",
      "Batch [ 200/2943], loss =  12.5737, recon_loss =  10.2988, kl_loss =   2.2749\n",
      "Batch [ 400/2943], loss =  12.1770, recon_loss =   9.8545, kl_loss =   2.3225\n",
      "Batch [ 600/2943], loss =  12.2050, recon_loss =   9.9115, kl_loss =   2.2935\n",
      "Batch [ 800/2943], loss =  12.7721, recon_loss =  10.4409, kl_loss =   2.3311\n",
      "Batch [1000/2943], loss =  13.5832, recon_loss =  11.3218, kl_loss =   2.2614\n",
      "Batch [1200/2943], loss =  12.6778, recon_loss =  10.4061, kl_loss =   2.2718\n",
      "Batch [1400/2943], loss =  13.3842, recon_loss =  11.1167, kl_loss =   2.2675\n",
      "Batch [1600/2943], loss =  13.2569, recon_loss =  10.9461, kl_loss =   2.3108\n",
      "Batch [1800/2943], loss =  13.9571, recon_loss =  11.7541, kl_loss =   2.2031\n",
      "Batch [2000/2943], loss =  12.0890, recon_loss =   9.8234, kl_loss =   2.2656\n",
      "Batch [2200/2943], loss =  11.9122, recon_loss =   9.5335, kl_loss =   2.3787\n",
      "Batch [2400/2943], loss =  13.7882, recon_loss =  11.5305, kl_loss =   2.2577\n",
      "Batch [2600/2943], loss =  13.2664, recon_loss =  10.9772, kl_loss =   2.2892\n",
      "Batch [2800/2943], loss =  12.0311, recon_loss =   9.7856, kl_loss =   2.2455\n",
      "Average loss: 12.8022\n",
      "Epoch: 15\n",
      "Batch [ 200/2943], loss =  11.4462, recon_loss =   9.2539, kl_loss =   2.1923\n",
      "Batch [ 400/2943], loss =   9.4542, recon_loss =   7.3117, kl_loss =   2.1425\n",
      "Batch [ 600/2943], loss =  11.9657, recon_loss =   9.7617, kl_loss =   2.2041\n",
      "Batch [ 800/2943], loss =  14.1589, recon_loss =  11.9463, kl_loss =   2.2126\n",
      "Batch [1000/2943], loss =  12.4949, recon_loss =  10.2506, kl_loss =   2.2443\n",
      "Batch [1200/2943], loss =  14.9966, recon_loss =  12.6940, kl_loss =   2.3026\n",
      "Batch [1400/2943], loss =  12.7596, recon_loss =  10.5316, kl_loss =   2.2281\n",
      "Batch [1600/2943], loss =  19.1749, recon_loss =  16.8834, kl_loss =   2.2915\n",
      "Batch [1800/2943], loss =  10.7768, recon_loss =   8.5962, kl_loss =   2.1806\n",
      "Batch [2000/2943], loss =   9.8593, recon_loss =   7.7342, kl_loss =   2.1251\n",
      "Batch [2200/2943], loss =  14.8818, recon_loss =  12.6335, kl_loss =   2.2483\n",
      "Batch [2400/2943], loss =  14.8037, recon_loss =  12.5168, kl_loss =   2.2869\n",
      "Batch [2600/2943], loss =  12.1931, recon_loss =   9.9690, kl_loss =   2.2241\n",
      "Batch [2800/2943], loss =  10.5804, recon_loss =   8.4281, kl_loss =   2.1523\n",
      "Average loss: 12.4254\n",
      "Epoch: 16\n",
      "Batch [ 200/2943], loss =   9.3901, recon_loss =   7.2930, kl_loss =   2.0971\n",
      "Batch [ 400/2943], loss =   9.4443, recon_loss =   7.3600, kl_loss =   2.0843\n",
      "Batch [ 600/2943], loss =  12.0443, recon_loss =   9.8745, kl_loss =   2.1699\n",
      "Batch [ 800/2943], loss =  13.2584, recon_loss =  11.0120, kl_loss =   2.2463\n",
      "Batch [1000/2943], loss =  13.0892, recon_loss =  10.9273, kl_loss =   2.1619\n",
      "Batch [1200/2943], loss =  12.4806, recon_loss =  10.3550, kl_loss =   2.1256\n",
      "Batch [1400/2943], loss =  11.9175, recon_loss =   9.7049, kl_loss =   2.2127\n",
      "Batch [1600/2943], loss =  11.6252, recon_loss =   9.4984, kl_loss =   2.1268\n",
      "Batch [1800/2943], loss =  10.9705, recon_loss =   8.7763, kl_loss =   2.1942\n",
      "Batch [2000/2943], loss =   8.9319, recon_loss =   6.8768, kl_loss =   2.0551\n",
      "Batch [2200/2943], loss =  12.9427, recon_loss =  10.7518, kl_loss =   2.1909\n",
      "Batch [2400/2943], loss =  12.9639, recon_loss =  10.7401, kl_loss =   2.2238\n",
      "Batch [2600/2943], loss =   9.1283, recon_loss =   7.0919, kl_loss =   2.0364\n",
      "Batch [2800/2943], loss =  11.3371, recon_loss =   9.2008, kl_loss =   2.1363\n",
      "Average loss: 12.0698\n",
      "Epoch: 17\n",
      "Batch [ 200/2943], loss =  12.3639, recon_loss =  10.2722, kl_loss =   2.0916\n",
      "Batch [ 400/2943], loss =  12.3705, recon_loss =  10.2469, kl_loss =   2.1237\n",
      "Batch [ 600/2943], loss =  10.8470, recon_loss =   8.7128, kl_loss =   2.1343\n",
      "Batch [ 800/2943], loss =  15.6524, recon_loss =  13.5760, kl_loss =   2.0764\n",
      "Batch [1000/2943], loss =  10.8840, recon_loss =   8.8009, kl_loss =   2.0831\n",
      "Batch [1200/2943], loss =   9.2231, recon_loss =   7.0971, kl_loss =   2.1260\n",
      "Batch [1400/2943], loss =  13.3256, recon_loss =  11.1669, kl_loss =   2.1588\n",
      "Batch [1600/2943], loss =  14.7607, recon_loss =  12.6284, kl_loss =   2.1322\n",
      "Batch [1800/2943], loss =   9.5495, recon_loss =   7.4285, kl_loss =   2.1210\n",
      "Batch [2000/2943], loss =  11.4467, recon_loss =   9.4481, kl_loss =   1.9986\n",
      "Batch [2200/2943], loss =  15.9338, recon_loss =  13.8500, kl_loss =   2.0839\n",
      "Batch [2400/2943], loss =  12.6054, recon_loss =  10.5246, kl_loss =   2.0808\n",
      "Batch [2600/2943], loss =  11.7873, recon_loss =   9.7024, kl_loss =   2.0849\n",
      "Batch [2800/2943], loss =  12.5624, recon_loss =  10.4325, kl_loss =   2.1299\n",
      "Average loss: 11.7661\n",
      "Epoch: 18\n",
      "Batch [ 200/2943], loss =  14.4526, recon_loss =  12.3688, kl_loss =   2.0838\n",
      "Batch [ 400/2943], loss =  13.4379, recon_loss =  11.3388, kl_loss =   2.0992\n",
      "Batch [ 600/2943], loss =  11.5423, recon_loss =   9.4009, kl_loss =   2.1414\n",
      "Batch [ 800/2943], loss =  10.4418, recon_loss =   8.4313, kl_loss =   2.0105\n",
      "Batch [1000/2943], loss =  12.8824, recon_loss =  10.7840, kl_loss =   2.0984\n",
      "Batch [1200/2943], loss =  13.6655, recon_loss =  11.6098, kl_loss =   2.0557\n",
      "Batch [1400/2943], loss =  12.5925, recon_loss =  10.5575, kl_loss =   2.0350\n",
      "Batch [1600/2943], loss =  12.6908, recon_loss =  10.6241, kl_loss =   2.0667\n",
      "Batch [1800/2943], loss =  10.1384, recon_loss =   8.1260, kl_loss =   2.0124\n",
      "Batch [2000/2943], loss =  13.8670, recon_loss =  11.8895, kl_loss =   1.9775\n",
      "Batch [2200/2943], loss =   9.5951, recon_loss =   7.5934, kl_loss =   2.0017\n",
      "Batch [2400/2943], loss =  12.1197, recon_loss =  10.0621, kl_loss =   2.0576\n",
      "Batch [2600/2943], loss =  11.4885, recon_loss =   9.4380, kl_loss =   2.0505\n",
      "Batch [2800/2943], loss =   9.3663, recon_loss =   7.3666, kl_loss =   1.9996\n",
      "Average loss: 11.4942\n",
      "Epoch: 19\n",
      "Batch [ 200/2943], loss =  12.2027, recon_loss =  10.1480, kl_loss =   2.0547\n",
      "Batch [ 400/2943], loss =  15.0353, recon_loss =  12.9375, kl_loss =   2.0978\n",
      "Batch [ 600/2943], loss =   9.1162, recon_loss =   7.1155, kl_loss =   2.0007\n",
      "Batch [ 800/2943], loss =  10.2374, recon_loss =   8.1430, kl_loss =   2.0944\n",
      "Batch [1000/2943], loss =   9.9490, recon_loss =   7.9016, kl_loss =   2.0474\n",
      "Batch [1200/2943], loss =  10.4342, recon_loss =   8.4580, kl_loss =   1.9763\n",
      "Batch [1400/2943], loss =   9.7280, recon_loss =   7.7046, kl_loss =   2.0234\n",
      "Batch [1600/2943], loss =  14.7865, recon_loss =  12.6338, kl_loss =   2.1527\n",
      "Batch [1800/2943], loss =  10.0494, recon_loss =   8.0548, kl_loss =   1.9946\n",
      "Batch [2000/2943], loss =   9.2138, recon_loss =   7.2219, kl_loss =   1.9920\n",
      "Batch [2200/2943], loss =  11.4397, recon_loss =   9.4725, kl_loss =   1.9672\n",
      "Batch [2400/2943], loss =  10.8910, recon_loss =   8.9157, kl_loss =   1.9753\n",
      "Batch [2600/2943], loss =  11.9823, recon_loss =   9.9194, kl_loss =   2.0629\n",
      "Batch [2800/2943], loss =  10.6644, recon_loss =   8.6663, kl_loss =   1.9980\n",
      "Average loss: 11.2401\n",
      "Epoch: 20\n",
      "Batch [ 200/2943], loss =  10.1761, recon_loss =   8.1723, kl_loss =   2.0037\n",
      "Batch [ 400/2943], loss =   9.9250, recon_loss =   7.8791, kl_loss =   2.0459\n",
      "Batch [ 600/2943], loss =  12.1768, recon_loss =  10.1698, kl_loss =   2.0070\n",
      "Batch [ 800/2943], loss =   8.8433, recon_loss =   6.8920, kl_loss =   1.9513\n",
      "Batch [1000/2943], loss =  10.9085, recon_loss =   8.9793, kl_loss =   1.9292\n",
      "Batch [1200/2943], loss =  10.2862, recon_loss =   8.3673, kl_loss =   1.9189\n",
      "Batch [1400/2943], loss =  11.8061, recon_loss =   9.8417, kl_loss =   1.9644\n",
      "Batch [1600/2943], loss =   9.6596, recon_loss =   7.7592, kl_loss =   1.9005\n",
      "Batch [1800/2943], loss =   9.3989, recon_loss =   7.5290, kl_loss =   1.8699\n",
      "Batch [2000/2943], loss =  10.7321, recon_loss =   8.8042, kl_loss =   1.9279\n",
      "Batch [2200/2943], loss =  14.6019, recon_loss =  12.6103, kl_loss =   1.9917\n",
      "Batch [2400/2943], loss =   9.7420, recon_loss =   7.8565, kl_loss =   1.8855\n",
      "Batch [2600/2943], loss =  12.9756, recon_loss =  10.9496, kl_loss =   2.0259\n",
      "Batch [2800/2943], loss =  12.9381, recon_loss =  10.9860, kl_loss =   1.9520\n",
      "Average loss: 11.0096\n",
      "Epoch: 21\n",
      "Batch [ 200/2943], loss =  11.9803, recon_loss =  10.0391, kl_loss =   1.9412\n",
      "Batch [ 400/2943], loss =   9.7830, recon_loss =   7.9202, kl_loss =   1.8628\n",
      "Batch [ 600/2943], loss =   9.9702, recon_loss =   8.0806, kl_loss =   1.8897\n",
      "Batch [ 800/2943], loss =   8.5906, recon_loss =   6.7128, kl_loss =   1.8778\n",
      "Batch [1000/2943], loss =  10.7752, recon_loss =   8.8989, kl_loss =   1.8763\n",
      "Batch [1200/2943], loss =   9.9737, recon_loss =   8.0697, kl_loss =   1.9039\n",
      "Batch [1400/2943], loss =  10.3296, recon_loss =   8.4224, kl_loss =   1.9072\n",
      "Batch [1600/2943], loss =  12.0293, recon_loss =  10.0972, kl_loss =   1.9322\n",
      "Batch [1800/2943], loss =  11.8012, recon_loss =   9.9197, kl_loss =   1.8815\n",
      "Batch [2000/2943], loss =   9.9499, recon_loss =   8.0909, kl_loss =   1.8590\n",
      "Batch [2200/2943], loss =   9.5645, recon_loss =   7.6602, kl_loss =   1.9042\n",
      "Batch [2400/2943], loss =   9.9881, recon_loss =   8.0856, kl_loss =   1.9025\n",
      "Batch [2600/2943], loss =  11.5291, recon_loss =   9.6358, kl_loss =   1.8933\n",
      "Batch [2800/2943], loss =  12.8761, recon_loss =  10.9674, kl_loss =   1.9087\n",
      "Average loss: 10.7754\n",
      "Epoch: 22\n",
      "Batch [ 200/2943], loss =   9.9838, recon_loss =   8.1117, kl_loss =   1.8721\n",
      "Batch [ 400/2943], loss =   9.6981, recon_loss =   7.8854, kl_loss =   1.8127\n",
      "Batch [ 600/2943], loss =  12.2815, recon_loss =  10.3484, kl_loss =   1.9331\n",
      "Batch [ 800/2943], loss =  10.9727, recon_loss =   9.0838, kl_loss =   1.8890\n",
      "Batch [1000/2943], loss =  12.7792, recon_loss =  10.8563, kl_loss =   1.9229\n",
      "Batch [1200/2943], loss =   8.2472, recon_loss =   6.4441, kl_loss =   1.8030\n",
      "Batch [1400/2943], loss =   9.6025, recon_loss =   7.7825, kl_loss =   1.8200\n",
      "Batch [1600/2943], loss =   9.3704, recon_loss =   7.5636, kl_loss =   1.8067\n",
      "Batch [1800/2943], loss =   9.7926, recon_loss =   7.8651, kl_loss =   1.9275\n",
      "Batch [2000/2943], loss =   8.8642, recon_loss =   7.0056, kl_loss =   1.8586\n",
      "Batch [2200/2943], loss =  10.1129, recon_loss =   8.2312, kl_loss =   1.8817\n",
      "Batch [2400/2943], loss =  13.6944, recon_loss =  11.7881, kl_loss =   1.9063\n",
      "Batch [2600/2943], loss =  11.1106, recon_loss =   9.2980, kl_loss =   1.8127\n",
      "Batch [2800/2943], loss =   9.8051, recon_loss =   7.9888, kl_loss =   1.8164\n",
      "Average loss: 10.5558\n",
      "Epoch: 23\n",
      "Batch [ 200/2943], loss =   9.0370, recon_loss =   7.2039, kl_loss =   1.8332\n",
      "Batch [ 400/2943], loss =  10.7162, recon_loss =   8.8428, kl_loss =   1.8734\n",
      "Batch [ 600/2943], loss =  11.7498, recon_loss =   9.8549, kl_loss =   1.8949\n",
      "Batch [ 800/2943], loss =   8.3000, recon_loss =   6.4527, kl_loss =   1.8473\n",
      "Batch [1000/2943], loss =   8.6018, recon_loss =   6.7830, kl_loss =   1.8187\n",
      "Batch [1200/2943], loss =  11.1906, recon_loss =   9.3683, kl_loss =   1.8224\n",
      "Batch [1400/2943], loss =   9.1380, recon_loss =   7.3590, kl_loss =   1.7790\n",
      "Batch [1600/2943], loss =  11.5907, recon_loss =   9.7234, kl_loss =   1.8673\n",
      "Batch [1800/2943], loss =  10.3329, recon_loss =   8.4426, kl_loss =   1.8904\n",
      "Batch [2000/2943], loss =   7.9694, recon_loss =   6.2005, kl_loss =   1.7690\n",
      "Batch [2200/2943], loss =  12.1230, recon_loss =  10.2488, kl_loss =   1.8742\n",
      "Batch [2400/2943], loss =   9.3211, recon_loss =   7.5644, kl_loss =   1.7567\n",
      "Batch [2600/2943], loss =  10.7215, recon_loss =   8.9316, kl_loss =   1.7899\n",
      "Batch [2800/2943], loss =   9.8956, recon_loss =   8.0951, kl_loss =   1.8005\n",
      "Average loss: 10.3370\n",
      "Epoch: 24\n",
      "Batch [ 200/2943], loss =   8.8090, recon_loss =   6.9819, kl_loss =   1.8271\n",
      "Batch [ 400/2943], loss =   9.1452, recon_loss =   7.3205, kl_loss =   1.8247\n",
      "Batch [ 600/2943], loss =  13.3808, recon_loss =  11.5998, kl_loss =   1.7810\n",
      "Batch [ 800/2943], loss =  11.1562, recon_loss =   9.2705, kl_loss =   1.8857\n",
      "Batch [1000/2943], loss =  12.4076, recon_loss =  10.5931, kl_loss =   1.8146\n",
      "Batch [1200/2943], loss =   9.9022, recon_loss =   8.1120, kl_loss =   1.7903\n",
      "Batch [1400/2943], loss =  10.5528, recon_loss =   8.7624, kl_loss =   1.7904\n",
      "Batch [1600/2943], loss =   9.4994, recon_loss =   7.7190, kl_loss =   1.7805\n",
      "Batch [1800/2943], loss =  12.1272, recon_loss =  10.3242, kl_loss =   1.8031\n",
      "Batch [2000/2943], loss =   9.7974, recon_loss =   7.9927, kl_loss =   1.8047\n",
      "Batch [2200/2943], loss =  10.1220, recon_loss =   8.3071, kl_loss =   1.8149\n",
      "Batch [2400/2943], loss =  10.9440, recon_loss =   9.2208, kl_loss =   1.7232\n",
      "Batch [2600/2943], loss =  11.7203, recon_loss =   9.8906, kl_loss =   1.8297\n",
      "Batch [2800/2943], loss =   7.8594, recon_loss =   6.1059, kl_loss =   1.7534\n",
      "Average loss: 10.1224\n",
      "Epoch: 25\n",
      "Batch [ 200/2943], loss =   9.8848, recon_loss =   8.1637, kl_loss =   1.7211\n",
      "Batch [ 400/2943], loss =   9.7026, recon_loss =   7.9188, kl_loss =   1.7838\n",
      "Batch [ 600/2943], loss =  10.1448, recon_loss =   8.4417, kl_loss =   1.7031\n",
      "Batch [ 800/2943], loss =  11.0047, recon_loss =   9.1851, kl_loss =   1.8197\n",
      "Batch [1000/2943], loss =   7.5351, recon_loss =   5.8239, kl_loss =   1.7113\n",
      "Batch [1200/2943], loss =  12.9704, recon_loss =  11.2437, kl_loss =   1.7267\n",
      "Batch [1400/2943], loss =   9.0705, recon_loss =   7.2363, kl_loss =   1.8342\n",
      "Batch [1600/2943], loss =   9.3324, recon_loss =   7.5938, kl_loss =   1.7386\n",
      "Batch [1800/2943], loss =  10.0908, recon_loss =   8.3288, kl_loss =   1.7620\n",
      "Batch [2000/2943], loss =  11.6560, recon_loss =   9.7968, kl_loss =   1.8592\n",
      "Batch [2200/2943], loss =   7.1010, recon_loss =   5.4274, kl_loss =   1.6736\n",
      "Batch [2400/2943], loss =   9.1430, recon_loss =   7.3830, kl_loss =   1.7600\n",
      "Batch [2600/2943], loss =  10.8092, recon_loss =   9.1062, kl_loss =   1.7029\n",
      "Batch [2800/2943], loss =   7.8537, recon_loss =   6.1434, kl_loss =   1.7103\n",
      "Average loss: 9.8883\n",
      "Epoch: 26\n",
      "Batch [ 200/2943], loss =   8.7211, recon_loss =   7.0145, kl_loss =   1.7066\n",
      "Batch [ 400/2943], loss =   8.1927, recon_loss =   6.4589, kl_loss =   1.7339\n",
      "Batch [ 600/2943], loss =   9.7386, recon_loss =   8.0053, kl_loss =   1.7333\n",
      "Batch [ 800/2943], loss =  15.2935, recon_loss =  13.5733, kl_loss =   1.7202\n",
      "Batch [1000/2943], loss =   8.9938, recon_loss =   7.2830, kl_loss =   1.7107\n",
      "Batch [1200/2943], loss =  17.0263, recon_loss =  15.2907, kl_loss =   1.7356\n",
      "Batch [1400/2943], loss =   9.2529, recon_loss =   7.5971, kl_loss =   1.6559\n",
      "Batch [1600/2943], loss =   8.9264, recon_loss =   7.2170, kl_loss =   1.7094\n",
      "Batch [1800/2943], loss =  10.1712, recon_loss =   8.4402, kl_loss =   1.7309\n",
      "Batch [2000/2943], loss =   8.6859, recon_loss =   6.9712, kl_loss =   1.7147\n",
      "Batch [2200/2943], loss =   8.3611, recon_loss =   6.7117, kl_loss =   1.6494\n",
      "Batch [2400/2943], loss =   7.4391, recon_loss =   5.7439, kl_loss =   1.6952\n",
      "Batch [2600/2943], loss =   9.3187, recon_loss =   7.6003, kl_loss =   1.7184\n",
      "Batch [2800/2943], loss =  10.2828, recon_loss =   8.5108, kl_loss =   1.7719\n",
      "Average loss: 9.6272\n",
      "Epoch: 27\n",
      "Batch [ 200/2943], loss =  12.4103, recon_loss =  10.7028, kl_loss =   1.7075\n",
      "Batch [ 400/2943], loss =  11.7477, recon_loss =  10.0092, kl_loss =   1.7385\n",
      "Batch [ 600/2943], loss =  12.8099, recon_loss =  11.1037, kl_loss =   1.7062\n",
      "Batch [ 800/2943], loss =   6.6062, recon_loss =   4.9682, kl_loss =   1.6381\n",
      "Batch [1000/2943], loss =   7.4857, recon_loss =   5.7919, kl_loss =   1.6938\n",
      "Batch [1200/2943], loss =   9.1085, recon_loss =   7.4208, kl_loss =   1.6877\n",
      "Batch [1400/2943], loss =  10.3602, recon_loss =   8.6474, kl_loss =   1.7127\n",
      "Batch [1600/2943], loss =   7.5582, recon_loss =   5.8900, kl_loss =   1.6682\n",
      "Batch [1800/2943], loss =   8.4136, recon_loss =   6.7160, kl_loss =   1.6976\n",
      "Batch [2000/2943], loss =   7.9353, recon_loss =   6.2719, kl_loss =   1.6634\n",
      "Batch [2200/2943], loss =  11.4185, recon_loss =   9.7030, kl_loss =   1.7155\n",
      "Batch [2400/2943], loss =  11.9688, recon_loss =  10.2133, kl_loss =   1.7555\n",
      "Batch [2600/2943], loss =   8.5435, recon_loss =   6.8257, kl_loss =   1.7178\n",
      "Batch [2800/2943], loss =   9.4802, recon_loss =   7.7856, kl_loss =   1.6946\n",
      "Average loss: 9.3281\n",
      "Epoch: 28\n",
      "Batch [ 200/2943], loss =   7.8653, recon_loss =   6.2261, kl_loss =   1.6392\n",
      "Batch [ 400/2943], loss =  11.0497, recon_loss =   9.2860, kl_loss =   1.7637\n",
      "Batch [ 600/2943], loss =   7.6912, recon_loss =   6.0196, kl_loss =   1.6716\n",
      "Batch [ 800/2943], loss =   8.2784, recon_loss =   6.5814, kl_loss =   1.6970\n",
      "Batch [1000/2943], loss =   6.2965, recon_loss =   4.6517, kl_loss =   1.6448\n",
      "Batch [1200/2943], loss =   9.8504, recon_loss =   8.2014, kl_loss =   1.6490\n",
      "Batch [1400/2943], loss =   7.6947, recon_loss =   6.0508, kl_loss =   1.6439\n",
      "Batch [1600/2943], loss =   8.4671, recon_loss =   6.7753, kl_loss =   1.6919\n",
      "Batch [1800/2943], loss =   8.3579, recon_loss =   6.7344, kl_loss =   1.6235\n",
      "Batch [2000/2943], loss =   6.0191, recon_loss =   4.4175, kl_loss =   1.6016\n",
      "Batch [2200/2943], loss =   7.4739, recon_loss =   5.8087, kl_loss =   1.6652\n",
      "Batch [2400/2943], loss =   8.0801, recon_loss =   6.4456, kl_loss =   1.6345\n",
      "Batch [2600/2943], loss =   6.8945, recon_loss =   5.2525, kl_loss =   1.6420\n",
      "Batch [2800/2943], loss =   6.7617, recon_loss =   5.1109, kl_loss =   1.6508\n",
      "Average loss: 8.9792\n",
      "Epoch: 29\n",
      "Batch [ 200/2943], loss =   7.6996, recon_loss =   6.0680, kl_loss =   1.6316\n",
      "Batch [ 400/2943], loss =  10.7174, recon_loss =   9.0471, kl_loss =   1.6703\n",
      "Batch [ 600/2943], loss =   8.5035, recon_loss =   6.8574, kl_loss =   1.6461\n",
      "Batch [ 800/2943], loss =   6.9053, recon_loss =   5.2589, kl_loss =   1.6464\n",
      "Batch [1000/2943], loss =   8.4869, recon_loss =   6.8402, kl_loss =   1.6467\n",
      "Batch [1200/2943], loss =   9.6393, recon_loss =   7.9994, kl_loss =   1.6398\n",
      "Batch [1400/2943], loss =   8.2606, recon_loss =   6.5873, kl_loss =   1.6733\n",
      "Batch [1600/2943], loss =   9.0233, recon_loss =   7.3826, kl_loss =   1.6407\n",
      "Batch [1800/2943], loss =   7.2264, recon_loss =   5.6045, kl_loss =   1.6219\n",
      "Batch [2000/2943], loss =   6.9602, recon_loss =   5.3329, kl_loss =   1.6273\n",
      "Batch [2200/2943], loss =   9.7880, recon_loss =   8.1061, kl_loss =   1.6819\n",
      "Batch [2400/2943], loss =  12.5503, recon_loss =  10.8508, kl_loss =   1.6996\n",
      "Batch [2600/2943], loss =   7.6131, recon_loss =   5.9592, kl_loss =   1.6539\n",
      "Batch [2800/2943], loss =  10.5923, recon_loss =   8.8252, kl_loss =   1.7671\n",
      "Average loss: 8.6518\n",
      "Epoch: 30\n",
      "Batch [ 200/2943], loss =   7.8472, recon_loss =   6.1613, kl_loss =   1.6859\n",
      "Batch [ 400/2943], loss =   7.1238, recon_loss =   5.4782, kl_loss =   1.6456\n",
      "Batch [ 600/2943], loss =   7.3201, recon_loss =   5.6890, kl_loss =   1.6311\n",
      "Batch [ 800/2943], loss =   8.5587, recon_loss =   6.8910, kl_loss =   1.6677\n",
      "Batch [1000/2943], loss =   7.3947, recon_loss =   5.7343, kl_loss =   1.6604\n",
      "Batch [1200/2943], loss =   6.9660, recon_loss =   5.3695, kl_loss =   1.5965\n",
      "Batch [1400/2943], loss =   8.3673, recon_loss =   6.7303, kl_loss =   1.6371\n",
      "Batch [1600/2943], loss =   8.6653, recon_loss =   6.9529, kl_loss =   1.7124\n",
      "Batch [1800/2943], loss =   7.3747, recon_loss =   5.7739, kl_loss =   1.6008\n",
      "Batch [2000/2943], loss =  13.8364, recon_loss =  12.1931, kl_loss =   1.6432\n",
      "Batch [2200/2943], loss =   8.3436, recon_loss =   6.7219, kl_loss =   1.6217\n",
      "Batch [2400/2943], loss =   6.9292, recon_loss =   5.2846, kl_loss =   1.6446\n",
      "Batch [2600/2943], loss =   8.6287, recon_loss =   6.9648, kl_loss =   1.6639\n",
      "Batch [2800/2943], loss =   8.1402, recon_loss =   6.4668, kl_loss =   1.6733\n",
      "Average loss: 8.3970\n",
      "Epoch: 31\n",
      "Batch [ 200/2943], loss =   7.2533, recon_loss =   5.6150, kl_loss =   1.6383\n",
      "Batch [ 400/2943], loss =   8.2529, recon_loss =   6.5498, kl_loss =   1.7031\n",
      "Batch [ 600/2943], loss =   6.3806, recon_loss =   4.7732, kl_loss =   1.6074\n",
      "Batch [ 800/2943], loss =   8.4945, recon_loss =   6.8409, kl_loss =   1.6535\n",
      "Batch [1000/2943], loss =   8.9421, recon_loss =   7.3105, kl_loss =   1.6315\n",
      "Batch [1200/2943], loss =   8.2039, recon_loss =   6.5532, kl_loss =   1.6507\n",
      "Batch [1400/2943], loss =   8.2939, recon_loss =   6.6377, kl_loss =   1.6562\n",
      "Batch [1600/2943], loss =   6.6117, recon_loss =   5.0014, kl_loss =   1.6103\n",
      "Batch [1800/2943], loss =   8.2836, recon_loss =   6.6551, kl_loss =   1.6285\n",
      "Batch [2000/2943], loss =   7.6849, recon_loss =   6.0243, kl_loss =   1.6605\n",
      "Batch [2200/2943], loss =   9.5564, recon_loss =   7.8626, kl_loss =   1.6938\n",
      "Batch [2400/2943], loss =   9.3362, recon_loss =   7.7120, kl_loss =   1.6241\n",
      "Batch [2600/2943], loss =   7.7972, recon_loss =   6.1347, kl_loss =   1.6625\n",
      "Batch [2800/2943], loss =   7.4863, recon_loss =   5.8600, kl_loss =   1.6264\n",
      "Average loss: 8.1857\n",
      "Epoch: 32\n",
      "Batch [ 200/2943], loss =   6.2393, recon_loss =   4.6280, kl_loss =   1.6114\n",
      "Batch [ 400/2943], loss =   8.1800, recon_loss =   6.5373, kl_loss =   1.6427\n",
      "Batch [ 600/2943], loss =   9.7935, recon_loss =   8.1459, kl_loss =   1.6476\n",
      "Batch [ 800/2943], loss =   9.6091, recon_loss =   8.0396, kl_loss =   1.5695\n",
      "Batch [1000/2943], loss =   6.4926, recon_loss =   4.9119, kl_loss =   1.5807\n",
      "Batch [1200/2943], loss =   6.8911, recon_loss =   5.2703, kl_loss =   1.6208\n",
      "Batch [1400/2943], loss =   8.0548, recon_loss =   6.4532, kl_loss =   1.6016\n",
      "Batch [1600/2943], loss =   6.0871, recon_loss =   4.5007, kl_loss =   1.5864\n",
      "Batch [1800/2943], loss =  10.1504, recon_loss =   8.4870, kl_loss =   1.6634\n",
      "Batch [2000/2943], loss =   9.0346, recon_loss =   7.3907, kl_loss =   1.6439\n",
      "Batch [2200/2943], loss =  10.9655, recon_loss =   9.3459, kl_loss =   1.6196\n",
      "Batch [2400/2943], loss =   6.7431, recon_loss =   5.1419, kl_loss =   1.6012\n",
      "Batch [2600/2943], loss =   7.8290, recon_loss =   6.2061, kl_loss =   1.6229\n",
      "Batch [2800/2943], loss =   7.2792, recon_loss =   5.7171, kl_loss =   1.5622\n",
      "Average loss: 7.9898\n",
      "Epoch: 33\n",
      "Batch [ 200/2943], loss =   7.7373, recon_loss =   6.0548, kl_loss =   1.6824\n",
      "Batch [ 400/2943], loss =   8.6570, recon_loss =   7.0237, kl_loss =   1.6333\n",
      "Batch [ 600/2943], loss =   5.8712, recon_loss =   4.3151, kl_loss =   1.5562\n",
      "Batch [ 800/2943], loss =   7.5188, recon_loss =   5.8843, kl_loss =   1.6345\n",
      "Batch [1000/2943], loss =   6.1108, recon_loss =   4.5487, kl_loss =   1.5621\n",
      "Batch [1200/2943], loss =   7.5729, recon_loss =   5.9072, kl_loss =   1.6658\n",
      "Batch [1400/2943], loss =   6.7174, recon_loss =   5.0212, kl_loss =   1.6962\n",
      "Batch [1600/2943], loss =   6.2066, recon_loss =   4.6405, kl_loss =   1.5661\n",
      "Batch [1800/2943], loss =   8.9219, recon_loss =   7.2577, kl_loss =   1.6642\n",
      "Batch [2000/2943], loss =   8.5945, recon_loss =   6.9642, kl_loss =   1.6303\n",
      "Batch [2200/2943], loss =   7.2429, recon_loss =   5.6058, kl_loss =   1.6371\n",
      "Batch [2400/2943], loss =   5.9212, recon_loss =   4.3434, kl_loss =   1.5778\n",
      "Batch [2600/2943], loss =   8.1279, recon_loss =   6.5740, kl_loss =   1.5539\n",
      "Batch [2800/2943], loss =   9.2755, recon_loss =   7.5870, kl_loss =   1.6885\n",
      "Average loss: 7.8209\n",
      "Epoch: 34\n",
      "Batch [ 200/2943], loss =   6.7649, recon_loss =   5.1323, kl_loss =   1.6326\n",
      "Batch [ 400/2943], loss =   6.8027, recon_loss =   5.2230, kl_loss =   1.5797\n",
      "Batch [ 600/2943], loss =   7.8866, recon_loss =   6.2020, kl_loss =   1.6846\n",
      "Batch [ 800/2943], loss =   7.4404, recon_loss =   5.8640, kl_loss =   1.5764\n",
      "Batch [1000/2943], loss =   6.9699, recon_loss =   5.3638, kl_loss =   1.6060\n",
      "Batch [1200/2943], loss =   9.1351, recon_loss =   7.5036, kl_loss =   1.6315\n",
      "Batch [1400/2943], loss =   7.0855, recon_loss =   5.4958, kl_loss =   1.5897\n",
      "Batch [1600/2943], loss =   7.5395, recon_loss =   5.9038, kl_loss =   1.6357\n",
      "Batch [1800/2943], loss =   8.3629, recon_loss =   6.7960, kl_loss =   1.5669\n",
      "Batch [2000/2943], loss =   7.2864, recon_loss =   5.6951, kl_loss =   1.5912\n",
      "Batch [2200/2943], loss =   8.7199, recon_loss =   7.0892, kl_loss =   1.6307\n",
      "Batch [2400/2943], loss =   8.1440, recon_loss =   6.4977, kl_loss =   1.6463\n",
      "Batch [2600/2943], loss =   7.3694, recon_loss =   5.7502, kl_loss =   1.6192\n",
      "Batch [2800/2943], loss =   8.2360, recon_loss =   6.5721, kl_loss =   1.6638\n",
      "Average loss: 7.6683\n",
      "Epoch: 35\n",
      "Batch [ 200/2943], loss =   6.7770, recon_loss =   5.1736, kl_loss =   1.6034\n",
      "Batch [ 400/2943], loss =   6.1174, recon_loss =   4.4978, kl_loss =   1.6196\n",
      "Batch [ 600/2943], loss =   9.1897, recon_loss =   7.5682, kl_loss =   1.6215\n",
      "Batch [ 800/2943], loss =   6.5642, recon_loss =   4.9755, kl_loss =   1.5887\n",
      "Batch [1000/2943], loss =   7.6297, recon_loss =   6.0173, kl_loss =   1.6124\n",
      "Batch [1200/2943], loss =   5.8459, recon_loss =   4.3010, kl_loss =   1.5449\n",
      "Batch [1400/2943], loss =   5.7520, recon_loss =   4.1337, kl_loss =   1.6184\n",
      "Batch [1600/2943], loss =   6.9482, recon_loss =   5.3537, kl_loss =   1.5945\n",
      "Batch [1800/2943], loss =   7.5164, recon_loss =   5.8751, kl_loss =   1.6413\n",
      "Batch [2000/2943], loss =   7.8324, recon_loss =   6.2128, kl_loss =   1.6195\n",
      "Batch [2200/2943], loss =   6.7629, recon_loss =   5.1581, kl_loss =   1.6047\n",
      "Batch [2400/2943], loss =   6.0487, recon_loss =   4.4832, kl_loss =   1.5654\n",
      "Batch [2600/2943], loss =   6.7295, recon_loss =   5.0981, kl_loss =   1.6314\n",
      "Batch [2800/2943], loss =   6.7757, recon_loss =   5.1785, kl_loss =   1.5971\n",
      "Average loss: 7.5265\n",
      "Epoch: 36\n",
      "Batch [ 200/2943], loss =   6.3844, recon_loss =   4.7783, kl_loss =   1.6061\n",
      "Batch [ 400/2943], loss =   7.2817, recon_loss =   5.6908, kl_loss =   1.5910\n",
      "Batch [ 600/2943], loss =   7.0074, recon_loss =   5.4258, kl_loss =   1.5816\n",
      "Batch [ 800/2943], loss =   7.8333, recon_loss =   6.2617, kl_loss =   1.5716\n",
      "Batch [1000/2943], loss =   6.5040, recon_loss =   4.9356, kl_loss =   1.5684\n",
      "Batch [1200/2943], loss =   8.3847, recon_loss =   6.7856, kl_loss =   1.5991\n",
      "Batch [1400/2943], loss =   8.5870, recon_loss =   6.9553, kl_loss =   1.6317\n",
      "Batch [1600/2943], loss =   6.2947, recon_loss =   4.7169, kl_loss =   1.5778\n",
      "Batch [1800/2943], loss =   6.2972, recon_loss =   4.6844, kl_loss =   1.6129\n",
      "Batch [2000/2943], loss =   9.2202, recon_loss =   7.5533, kl_loss =   1.6669\n",
      "Batch [2200/2943], loss =   7.5647, recon_loss =   5.9526, kl_loss =   1.6120\n",
      "Batch [2400/2943], loss =   6.9634, recon_loss =   5.3385, kl_loss =   1.6250\n",
      "Batch [2600/2943], loss =   6.4625, recon_loss =   4.8773, kl_loss =   1.5853\n",
      "Batch [2800/2943], loss =   7.5974, recon_loss =   5.9874, kl_loss =   1.6100\n",
      "Average loss: 7.3880\n",
      "Epoch: 37\n",
      "Batch [ 200/2943], loss =   7.0349, recon_loss =   5.4223, kl_loss =   1.6125\n",
      "Batch [ 400/2943], loss =   6.3805, recon_loss =   4.8352, kl_loss =   1.5453\n",
      "Batch [ 600/2943], loss =   7.9200, recon_loss =   6.2764, kl_loss =   1.6436\n",
      "Batch [ 800/2943], loss =   7.5046, recon_loss =   5.9035, kl_loss =   1.6011\n",
      "Batch [1000/2943], loss =   9.3606, recon_loss =   7.7293, kl_loss =   1.6313\n",
      "Batch [1200/2943], loss =   5.5878, recon_loss =   4.0096, kl_loss =   1.5782\n",
      "Batch [1400/2943], loss =   6.0436, recon_loss =   4.4278, kl_loss =   1.6158\n",
      "Batch [1600/2943], loss =   7.6674, recon_loss =   6.0971, kl_loss =   1.5703\n",
      "Batch [1800/2943], loss =   7.5345, recon_loss =   5.9597, kl_loss =   1.5748\n",
      "Batch [2000/2943], loss =   5.7802, recon_loss =   4.2286, kl_loss =   1.5517\n",
      "Batch [2200/2943], loss =   7.9727, recon_loss =   6.3579, kl_loss =   1.6148\n",
      "Batch [2400/2943], loss =   7.9987, recon_loss =   6.3668, kl_loss =   1.6319\n",
      "Batch [2600/2943], loss =   5.8710, recon_loss =   4.3156, kl_loss =   1.5554\n",
      "Batch [2800/2943], loss =   6.0738, recon_loss =   4.5267, kl_loss =   1.5471\n",
      "Average loss: 7.2798\n",
      "Epoch: 38\n",
      "Batch [ 200/2943], loss =   5.9274, recon_loss =   4.3922, kl_loss =   1.5351\n",
      "Batch [ 400/2943], loss =   7.0693, recon_loss =   5.4593, kl_loss =   1.6100\n",
      "Batch [ 600/2943], loss =   8.4354, recon_loss =   6.8267, kl_loss =   1.6087\n",
      "Batch [ 800/2943], loss =   6.1157, recon_loss =   4.5695, kl_loss =   1.5462\n",
      "Batch [1000/2943], loss =   6.0195, recon_loss =   4.4915, kl_loss =   1.5280\n",
      "Batch [1200/2943], loss =   6.4476, recon_loss =   4.8135, kl_loss =   1.6341\n",
      "Batch [1400/2943], loss =   5.9513, recon_loss =   4.3946, kl_loss =   1.5567\n",
      "Batch [1600/2943], loss =   5.6687, recon_loss =   4.1083, kl_loss =   1.5604\n",
      "Batch [1800/2943], loss =   7.5119, recon_loss =   5.9111, kl_loss =   1.6008\n",
      "Batch [2000/2943], loss =   7.2667, recon_loss =   5.6688, kl_loss =   1.5979\n",
      "Batch [2200/2943], loss =   6.2540, recon_loss =   4.6734, kl_loss =   1.5806\n",
      "Batch [2400/2943], loss =   6.1369, recon_loss =   4.5768, kl_loss =   1.5601\n",
      "Batch [2600/2943], loss =   7.7629, recon_loss =   6.2290, kl_loss =   1.5340\n",
      "Batch [2800/2943], loss =   8.1600, recon_loss =   6.5957, kl_loss =   1.5643\n",
      "Average loss: 7.1704\n",
      "Epoch: 39\n",
      "Batch [ 200/2943], loss =   6.4046, recon_loss =   4.8662, kl_loss =   1.5384\n",
      "Batch [ 400/2943], loss =   6.1091, recon_loss =   4.5801, kl_loss =   1.5289\n",
      "Batch [ 600/2943], loss =   6.6321, recon_loss =   5.0560, kl_loss =   1.5761\n",
      "Batch [ 800/2943], loss =   7.0305, recon_loss =   5.4581, kl_loss =   1.5724\n",
      "Batch [1000/2943], loss =   7.5613, recon_loss =   5.9831, kl_loss =   1.5782\n",
      "Batch [1200/2943], loss =   7.6771, recon_loss =   6.0722, kl_loss =   1.6049\n",
      "Batch [1400/2943], loss =   5.2494, recon_loss =   3.7394, kl_loss =   1.5100\n",
      "Batch [1600/2943], loss =   5.7917, recon_loss =   4.2252, kl_loss =   1.5665\n",
      "Batch [1800/2943], loss =   8.4524, recon_loss =   6.8521, kl_loss =   1.6003\n",
      "Batch [2000/2943], loss =   6.9907, recon_loss =   5.4185, kl_loss =   1.5722\n",
      "Batch [2200/2943], loss =   8.2206, recon_loss =   6.6406, kl_loss =   1.5799\n",
      "Batch [2400/2943], loss =   7.3565, recon_loss =   5.8052, kl_loss =   1.5513\n",
      "Batch [2600/2943], loss =   8.4244, recon_loss =   6.8389, kl_loss =   1.5855\n",
      "Batch [2800/2943], loss =   5.6035, recon_loss =   4.0916, kl_loss =   1.5119\n",
      "Average loss: 7.0728\n",
      "Epoch: 40\n",
      "Batch [ 200/2943], loss =   7.0640, recon_loss =   5.4423, kl_loss =   1.6217\n",
      "Batch [ 400/2943], loss =   7.1648, recon_loss =   5.5535, kl_loss =   1.6113\n",
      "Batch [ 600/2943], loss =   7.8364, recon_loss =   6.2405, kl_loss =   1.5959\n",
      "Batch [ 800/2943], loss =   6.0145, recon_loss =   4.4955, kl_loss =   1.5189\n",
      "Batch [1000/2943], loss =   5.3304, recon_loss =   3.8022, kl_loss =   1.5282\n",
      "Batch [1200/2943], loss =   6.3766, recon_loss =   4.8291, kl_loss =   1.5475\n",
      "Batch [1400/2943], loss =   6.9518, recon_loss =   5.3892, kl_loss =   1.5626\n",
      "Batch [1600/2943], loss =   5.9689, recon_loss =   4.4768, kl_loss =   1.4920\n",
      "Batch [1800/2943], loss =   6.4596, recon_loss =   4.9253, kl_loss =   1.5343\n",
      "Batch [2000/2943], loss =   7.2369, recon_loss =   5.6996, kl_loss =   1.5372\n",
      "Batch [2200/2943], loss =   7.5409, recon_loss =   6.0025, kl_loss =   1.5384\n",
      "Batch [2400/2943], loss =   6.5204, recon_loss =   4.9844, kl_loss =   1.5360\n",
      "Batch [2600/2943], loss =   6.4706, recon_loss =   4.9369, kl_loss =   1.5337\n",
      "Batch [2800/2943], loss =   8.3949, recon_loss =   6.8261, kl_loss =   1.5689\n",
      "Average loss: 6.9660\n",
      "Epoch: 41\n",
      "Batch [ 200/2943], loss =   6.5855, recon_loss =   5.0134, kl_loss =   1.5721\n",
      "Batch [ 400/2943], loss =   7.1268, recon_loss =   5.5244, kl_loss =   1.6024\n",
      "Batch [ 600/2943], loss =   6.1111, recon_loss =   4.5498, kl_loss =   1.5613\n",
      "Batch [ 800/2943], loss =   5.4084, recon_loss =   3.9032, kl_loss =   1.5052\n",
      "Batch [1000/2943], loss =   6.9313, recon_loss =   5.3635, kl_loss =   1.5678\n",
      "Batch [1200/2943], loss =   7.5141, recon_loss =   5.9498, kl_loss =   1.5643\n",
      "Batch [1400/2943], loss =   5.3718, recon_loss =   3.8366, kl_loss =   1.5352\n",
      "Batch [1600/2943], loss =   7.0865, recon_loss =   5.5390, kl_loss =   1.5475\n",
      "Batch [1800/2943], loss =   8.2477, recon_loss =   6.7183, kl_loss =   1.5295\n",
      "Batch [2000/2943], loss =   7.4042, recon_loss =   5.8285, kl_loss =   1.5758\n",
      "Batch [2200/2943], loss =   7.7943, recon_loss =   6.2206, kl_loss =   1.5736\n",
      "Batch [2400/2943], loss =   6.4280, recon_loss =   4.8926, kl_loss =   1.5353\n",
      "Batch [2600/2943], loss =   5.5668, recon_loss =   4.0386, kl_loss =   1.5283\n",
      "Batch [2800/2943], loss =   7.7023, recon_loss =   6.1800, kl_loss =   1.5223\n",
      "Average loss: 6.8900\n",
      "Epoch: 42\n",
      "Batch [ 200/2943], loss =   7.8893, recon_loss =   6.3012, kl_loss =   1.5881\n",
      "Batch [ 400/2943], loss =   8.6348, recon_loss =   7.0690, kl_loss =   1.5658\n",
      "Batch [ 600/2943], loss =   5.5129, recon_loss =   3.9567, kl_loss =   1.5562\n",
      "Batch [ 800/2943], loss =   7.3497, recon_loss =   5.7677, kl_loss =   1.5820\n",
      "Batch [1000/2943], loss =  10.5425, recon_loss =   8.9525, kl_loss =   1.5900\n",
      "Batch [1200/2943], loss =   5.7147, recon_loss =   4.1893, kl_loss =   1.5254\n",
      "Batch [1400/2943], loss =   7.6910, recon_loss =   6.0939, kl_loss =   1.5971\n",
      "Batch [1600/2943], loss =   7.1456, recon_loss =   5.5746, kl_loss =   1.5710\n",
      "Batch [1800/2943], loss =   6.3776, recon_loss =   4.8196, kl_loss =   1.5580\n",
      "Batch [2000/2943], loss =   7.6442, recon_loss =   6.0700, kl_loss =   1.5742\n",
      "Batch [2200/2943], loss =   7.1160, recon_loss =   5.5731, kl_loss =   1.5429\n",
      "Batch [2400/2943], loss =   6.2137, recon_loss =   4.6634, kl_loss =   1.5503\n",
      "Batch [2600/2943], loss =   6.5207, recon_loss =   4.9725, kl_loss =   1.5483\n",
      "Batch [2800/2943], loss =   7.6406, recon_loss =   6.0521, kl_loss =   1.5884\n",
      "Average loss: 6.8004\n",
      "Epoch: 43\n",
      "Batch [ 200/2943], loss =   7.0439, recon_loss =   5.4405, kl_loss =   1.6034\n",
      "Batch [ 400/2943], loss =   7.5507, recon_loss =   5.9689, kl_loss =   1.5818\n",
      "Batch [ 600/2943], loss =   7.5742, recon_loss =   6.0011, kl_loss =   1.5732\n",
      "Batch [ 800/2943], loss =   6.6946, recon_loss =   5.1745, kl_loss =   1.5201\n",
      "Batch [1000/2943], loss =   8.6357, recon_loss =   7.0912, kl_loss =   1.5445\n",
      "Batch [1200/2943], loss =   6.8436, recon_loss =   5.2617, kl_loss =   1.5818\n",
      "Batch [1400/2943], loss =   6.2577, recon_loss =   4.7174, kl_loss =   1.5404\n",
      "Batch [1600/2943], loss =   7.8712, recon_loss =   6.3222, kl_loss =   1.5490\n",
      "Batch [1800/2943], loss =   7.1045, recon_loss =   5.5482, kl_loss =   1.5563\n",
      "Batch [2000/2943], loss =   6.3672, recon_loss =   4.8714, kl_loss =   1.4958\n",
      "Batch [2200/2943], loss =   6.5259, recon_loss =   4.9607, kl_loss =   1.5652\n",
      "Batch [2400/2943], loss =   6.7025, recon_loss =   5.1530, kl_loss =   1.5495\n",
      "Batch [2600/2943], loss =   6.0680, recon_loss =   4.5080, kl_loss =   1.5601\n",
      "Batch [2800/2943], loss =   7.1902, recon_loss =   5.6290, kl_loss =   1.5611\n",
      "Average loss: 6.7318\n",
      "Epoch: 44\n",
      "Batch [ 200/2943], loss =   7.0301, recon_loss =   5.4680, kl_loss =   1.5621\n",
      "Batch [ 400/2943], loss =   6.8041, recon_loss =   5.2681, kl_loss =   1.5360\n",
      "Batch [ 600/2943], loss =   6.9639, recon_loss =   5.3449, kl_loss =   1.6190\n",
      "Batch [ 800/2943], loss =   5.5533, recon_loss =   4.0445, kl_loss =   1.5088\n",
      "Batch [1000/2943], loss =   7.3030, recon_loss =   5.7344, kl_loss =   1.5686\n",
      "Batch [1200/2943], loss =   6.8592, recon_loss =   5.3104, kl_loss =   1.5489\n",
      "Batch [1400/2943], loss =   5.3653, recon_loss =   3.8764, kl_loss =   1.4889\n",
      "Batch [1600/2943], loss =   5.5008, recon_loss =   4.0155, kl_loss =   1.4853\n",
      "Batch [1800/2943], loss =   5.5215, recon_loss =   3.9824, kl_loss =   1.5391\n",
      "Batch [2000/2943], loss =   5.6314, recon_loss =   4.0945, kl_loss =   1.5368\n",
      "Batch [2200/2943], loss =   6.6710, recon_loss =   5.1259, kl_loss =   1.5451\n",
      "Batch [2400/2943], loss =   7.3785, recon_loss =   5.7879, kl_loss =   1.5906\n",
      "Batch [2600/2943], loss =   5.6290, recon_loss =   4.1450, kl_loss =   1.4840\n",
      "Batch [2800/2943], loss =   6.0633, recon_loss =   4.5421, kl_loss =   1.5212\n",
      "Average loss: 6.6391\n",
      "Epoch: 45\n",
      "Batch [ 200/2943], loss =   6.4621, recon_loss =   4.9025, kl_loss =   1.5596\n",
      "Batch [ 400/2943], loss =   6.4662, recon_loss =   4.9138, kl_loss =   1.5524\n",
      "Batch [ 600/2943], loss =   7.0835, recon_loss =   5.5335, kl_loss =   1.5500\n",
      "Batch [ 800/2943], loss =   6.1987, recon_loss =   4.6591, kl_loss =   1.5396\n",
      "Batch [1000/2943], loss =   5.2507, recon_loss =   3.7804, kl_loss =   1.4703\n",
      "Batch [1200/2943], loss =   6.2566, recon_loss =   4.7406, kl_loss =   1.5160\n",
      "Batch [1400/2943], loss =   7.3122, recon_loss =   5.7078, kl_loss =   1.6043\n",
      "Batch [1600/2943], loss =   7.5081, recon_loss =   5.9673, kl_loss =   1.5408\n",
      "Batch [1800/2943], loss =   7.7628, recon_loss =   6.2031, kl_loss =   1.5597\n",
      "Batch [2000/2943], loss =   7.6766, recon_loss =   6.1091, kl_loss =   1.5675\n",
      "Batch [2200/2943], loss =   5.6458, recon_loss =   4.1561, kl_loss =   1.4896\n",
      "Batch [2400/2943], loss =   5.6006, recon_loss =   4.0918, kl_loss =   1.5088\n",
      "Batch [2600/2943], loss =   6.6926, recon_loss =   5.1824, kl_loss =   1.5102\n",
      "Batch [2800/2943], loss =   5.7630, recon_loss =   4.2492, kl_loss =   1.5138\n",
      "Average loss: 6.5519\n",
      "Epoch: 46\n",
      "Batch [ 200/2943], loss =   5.2734, recon_loss =   3.7480, kl_loss =   1.5254\n",
      "Batch [ 400/2943], loss =   7.7983, recon_loss =   6.2702, kl_loss =   1.5281\n",
      "Batch [ 600/2943], loss =   5.9070, recon_loss =   4.3649, kl_loss =   1.5421\n",
      "Batch [ 800/2943], loss =   5.9687, recon_loss =   4.4458, kl_loss =   1.5229\n",
      "Batch [1000/2943], loss =   7.5162, recon_loss =   5.9401, kl_loss =   1.5761\n",
      "Batch [1200/2943], loss =   6.4865, recon_loss =   4.8995, kl_loss =   1.5871\n",
      "Batch [1400/2943], loss =   5.1502, recon_loss =   3.6588, kl_loss =   1.4914\n",
      "Batch [1600/2943], loss =   6.4474, recon_loss =   4.9373, kl_loss =   1.5102\n",
      "Batch [1800/2943], loss =   6.9707, recon_loss =   5.4208, kl_loss =   1.5499\n",
      "Batch [2000/2943], loss =   5.6202, recon_loss =   4.0865, kl_loss =   1.5337\n",
      "Batch [2200/2943], loss =   6.0192, recon_loss =   4.4961, kl_loss =   1.5231\n",
      "Batch [2400/2943], loss =   5.7594, recon_loss =   4.2138, kl_loss =   1.5456\n",
      "Batch [2600/2943], loss =   7.6957, recon_loss =   6.1073, kl_loss =   1.5884\n",
      "Batch [2800/2943], loss =   6.3686, recon_loss =   4.8446, kl_loss =   1.5240\n",
      "Average loss: 6.4557\n",
      "Epoch: 47\n",
      "Batch [ 200/2943], loss =   6.8633, recon_loss =   5.2437, kl_loss =   1.6196\n",
      "Batch [ 400/2943], loss =   7.1218, recon_loss =   5.5778, kl_loss =   1.5440\n",
      "Batch [ 600/2943], loss =   6.1760, recon_loss =   4.6690, kl_loss =   1.5069\n",
      "Batch [ 800/2943], loss =   5.7849, recon_loss =   4.2683, kl_loss =   1.5166\n",
      "Batch [1000/2943], loss =   6.3364, recon_loss =   4.7872, kl_loss =   1.5492\n",
      "Batch [1200/2943], loss =   5.9000, recon_loss =   4.3789, kl_loss =   1.5211\n",
      "Batch [1400/2943], loss =   6.1558, recon_loss =   4.6679, kl_loss =   1.4879\n",
      "Batch [1600/2943], loss =   5.8611, recon_loss =   4.2980, kl_loss =   1.5631\n",
      "Batch [1800/2943], loss =   5.5610, recon_loss =   4.0483, kl_loss =   1.5127\n",
      "Batch [2000/2943], loss =   6.5005, recon_loss =   4.9666, kl_loss =   1.5339\n",
      "Batch [2200/2943], loss =   6.4886, recon_loss =   4.9481, kl_loss =   1.5405\n",
      "Batch [2400/2943], loss =   5.5284, recon_loss =   4.0569, kl_loss =   1.4716\n",
      "Batch [2600/2943], loss =   5.5680, recon_loss =   4.0433, kl_loss =   1.5247\n",
      "Batch [2800/2943], loss =   7.4146, recon_loss =   5.8420, kl_loss =   1.5726\n",
      "Average loss: 6.3674\n",
      "Epoch: 48\n",
      "Batch [ 200/2943], loss =   6.8886, recon_loss =   5.3755, kl_loss =   1.5131\n",
      "Batch [ 400/2943], loss =   6.9819, recon_loss =   5.4073, kl_loss =   1.5746\n",
      "Batch [ 600/2943], loss =   7.6498, recon_loss =   6.0402, kl_loss =   1.6096\n",
      "Batch [ 800/2943], loss =   6.4587, recon_loss =   4.9423, kl_loss =   1.5164\n",
      "Batch [1000/2943], loss =   5.4056, recon_loss =   3.9093, kl_loss =   1.4964\n",
      "Batch [1200/2943], loss =   6.0053, recon_loss =   4.4679, kl_loss =   1.5374\n",
      "Batch [1400/2943], loss =   6.1318, recon_loss =   4.6358, kl_loss =   1.4960\n",
      "Batch [1600/2943], loss =   5.2911, recon_loss =   3.8720, kl_loss =   1.4191\n",
      "Batch [1800/2943], loss =   5.2818, recon_loss =   3.7268, kl_loss =   1.5550\n",
      "Batch [2000/2943], loss =   5.6806, recon_loss =   4.1412, kl_loss =   1.5394\n",
      "Batch [2200/2943], loss =   5.7865, recon_loss =   4.2455, kl_loss =   1.5411\n",
      "Batch [2400/2943], loss =   8.2530, recon_loss =   6.7183, kl_loss =   1.5347\n",
      "Batch [2600/2943], loss =   6.0668, recon_loss =   4.5693, kl_loss =   1.4974\n",
      "Batch [2800/2943], loss =   5.3237, recon_loss =   3.7994, kl_loss =   1.5243\n",
      "Average loss: 6.2475\n",
      "Epoch: 49\n",
      "Batch [ 200/2943], loss =   5.9718, recon_loss =   4.4575, kl_loss =   1.5143\n",
      "Batch [ 400/2943], loss =   5.2826, recon_loss =   3.8028, kl_loss =   1.4798\n",
      "Batch [ 600/2943], loss =   5.2578, recon_loss =   3.7834, kl_loss =   1.4744\n",
      "Batch [ 800/2943], loss =   5.2570, recon_loss =   3.7475, kl_loss =   1.5095\n",
      "Batch [1000/2943], loss =   5.5515, recon_loss =   4.0319, kl_loss =   1.5196\n",
      "Batch [1200/2943], loss =   5.7058, recon_loss =   4.1598, kl_loss =   1.5460\n",
      "Batch [1400/2943], loss =   8.4613, recon_loss =   6.9453, kl_loss =   1.5160\n",
      "Batch [1600/2943], loss =   5.2146, recon_loss =   3.7097, kl_loss =   1.5049\n",
      "Batch [1800/2943], loss =   7.2034, recon_loss =   5.6589, kl_loss =   1.5445\n",
      "Batch [2000/2943], loss =   5.4270, recon_loss =   3.9134, kl_loss =   1.5136\n",
      "Batch [2200/2943], loss =   4.6709, recon_loss =   3.2373, kl_loss =   1.4336\n",
      "Batch [2400/2943], loss =   6.3283, recon_loss =   4.8306, kl_loss =   1.4978\n",
      "Batch [2600/2943], loss =   5.5628, recon_loss =   4.0426, kl_loss =   1.5202\n",
      "Batch [2800/2943], loss =   5.8382, recon_loss =   4.3261, kl_loss =   1.5121\n",
      "Average loss: 6.1553\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset)\n",
    "model.save('SaveModel/vrae_s_model.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "x_decoded = model.reconstruct(test_dataset)\n",
    "x_decoded = x_decoded.swapaxes(0, 1)\n",
    "\n",
    "import os\n",
    "os.makedirs('buffer_recon', exist_ok=True)\n",
    "np.save('buffer_recon/vrae_recon_state.npy', x_decoded)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# np.set_printoptions(precision=4, suppress=True)\n",
    "# for i in range(seq_len):\n",
    "#     print('sequence id: {}'.format(i))\n",
    "#     print('original')\n",
    "#     print(episodes[0][i])\n",
    "#     print('reconstruct')\n",
    "#     print(x_decoded[0][i])\n",
    "#     print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_0_1\n",
      "[-0.0002  0.0774  0.2997  0.2321  0.1885  0.1649  0.154   0.1485  0.1438\n",
      "  0.1405  0.1373  0.1342  0.1311  0.127   0.1224  0.1143  0.1     0.0812\n",
      "  0.0629  0.0344 -0.3318  0.0001  0.0002  0.      0.     -0.0055  0.013\n",
      " -0.001   0.0942]\n",
      "recon_0_1\n",
      "[ 0.006   0.0709  0.3052  0.2343  0.1937  0.1696  0.1556  0.152   0.1453\n",
      "  0.1386  0.1364  0.1324  0.1276  0.1228  0.1224  0.111   0.1021  0.0762\n",
      "  0.0654  0.0335 -0.3363 -0.0016  0.0055  0.     -0.0047 -0.0045  0.0153\n",
      "  0.0107  0.0852]\n",
      "\n",
      "orig_1_0\n",
      "[-0.0002  0.0774  0.2997  0.2321  0.1885  0.1649  0.154   0.1485  0.1438\n",
      "  0.1405  0.1373  0.1342  0.1311  0.127   0.1224  0.1143  0.1     0.0812\n",
      "  0.0629  0.0344 -0.3318  0.0001  0.0002  0.      0.     -0.0055  0.013\n",
      " -0.001   0.0942]\n",
      "recon_1_0\n",
      "[ 0.0072  0.0772  0.2975  0.2363  0.1964  0.1779  0.1591  0.154   0.1471\n",
      "  0.1411  0.1437  0.1382  0.1323  0.1264  0.122   0.1126  0.0953  0.0796\n",
      "  0.0576  0.0375 -0.3409  0.0011  0.0055 -0.0001  0.0128  0.0163  0.018\n",
      "  0.0133  0.0861]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=4, suppress=True)\n",
    "print('orig_0_1')\n",
    "print(episodes[0][1])\n",
    "print('recon_0_1')\n",
    "print(x_decoded[0][1])\n",
    "print()\n",
    "print('orig_1_0')\n",
    "print(episodes[1][0])\n",
    "print('recon_1_0')\n",
    "print(x_decoded[1][0])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}